[
  {
    "objectID": "notes/selectivity.html",
    "href": "notes/selectivity.html",
    "title": "Selectivity",
    "section": "",
    "text": "Selectivity: relative vulnerability of a demographic group of the fished population to capture by a fishery or survey, with at least one demographic group being fully selected (Cadrin et al., 2015).\nSelectivity is a combination of two processes:\n\nthe relative probability of capture for a demographic group (i.e., contact selectivity; Miller and Fryer, 1999)\nproportion of the group that is available to the fishery in time and space (i.e., population selectivity; Miller and Fryer, 1999)\n\naka vulnerability\n\n\nAssessments models typically require a particular form of selection curve and estimates a population selectivity curve. Selectivity is used to link observed composition data to model predictions about population abundance-at-age/-size. If multiple gear types operate in the fishery, or if the catch-at-age compositions from different segments of the fleet have distinct characteristics, then the catch-at-age data can be partitioned into separate matrices for each gear or fleet type with separate selectivity curves and parameters for each type.\n\n\nSelectivity is the portion of a demographic group that is vulnerable to capture by fishing:\n\\[\nF_{t,a} = F_t s_a\n\\tag{1}\\]\n\n\\(F_t\\) is fishing mortality at time \\(t\\) for fully-vulnerable ages (i.e., a year-specific fishing mortality multiplier)\n\ntypically managed through limiting total fishing effort in a year\n\n\\(s_a\\) is the selectivity of the age group\n\ntypically managed by regulating fishing technology and behavior\n\n\nThis definition is typically used for age-structure population models, but the same equation can be related to any other demographic groups (e.g., size intervals, life history stages). Eq 1 quantifies either constant or average selectivity during the time interval. The function expressed in eq 1 is termed separability because \\(F_{t,a}\\) can be separated into the components \\(F_t\\) and \\(s_a\\).\nRecall that catchability (\\(q\\)) is the effect of of a unit of fishing effort (\\(E\\)) directed on the population, with the effect measured as the exponential rate of fishing mortality imposed on the population over a time interval \\(t\\):\n\\[\nF_t = q E_t\n\\tag{2}\\]\nConsidering that catchability and selectivity have a relationship with fishing mortality, Eq 1 & 2 can be combined:\n\\[\nF_{t,a} = s_a q E_t; \\hspace{4mm} q_a = s_a  q\n\\tag{3}\\]\nSelectivity then plays an essential role as a component of the survival equation in abundance at age:\n\\[\nN_{t,a} = N_{t-1,a-1}e^{-(F_{t-1} s_{a-1} + M_{t-1,a-1})}\n\\tag{4}\\]\n\n\\(N_{t,a}\\) is the abundance of survivors of an age class at the end of year \\(t\\)\n\nEq 4 is the primary process equation for all age-structured stock assessment models."
  },
  {
    "objectID": "notes/selectivity.html#definition-of-selectivity",
    "href": "notes/selectivity.html#definition-of-selectivity",
    "title": "Selectivity",
    "section": "",
    "text": "Selectivity: relative vulnerability of a demographic group of the fished population to capture by a fishery or survey, with at least one demographic group being fully selected (Cadrin et al., 2015).\nSelectivity is a combination of two processes:\n\nthe relative probability of capture for a demographic group (i.e., contact selectivity; Miller and Fryer, 1999)\nproportion of the group that is available to the fishery in time and space (i.e., population selectivity; Miller and Fryer, 1999)\n\naka vulnerability\n\n\nAssessments models typically require a particular form of selection curve and estimates a population selectivity curve. Selectivity is used to link observed composition data to model predictions about population abundance-at-age/-size. If multiple gear types operate in the fishery, or if the catch-at-age compositions from different segments of the fleet have distinct characteristics, then the catch-at-age data can be partitioned into separate matrices for each gear or fleet type with separate selectivity curves and parameters for each type.\n\n\nSelectivity is the portion of a demographic group that is vulnerable to capture by fishing:\n\\[\nF_{t,a} = F_t s_a\n\\tag{1}\\]\n\n\\(F_t\\) is fishing mortality at time \\(t\\) for fully-vulnerable ages (i.e., a year-specific fishing mortality multiplier)\n\ntypically managed through limiting total fishing effort in a year\n\n\\(s_a\\) is the selectivity of the age group\n\ntypically managed by regulating fishing technology and behavior\n\n\nThis definition is typically used for age-structure population models, but the same equation can be related to any other demographic groups (e.g., size intervals, life history stages). Eq 1 quantifies either constant or average selectivity during the time interval. The function expressed in eq 1 is termed separability because \\(F_{t,a}\\) can be separated into the components \\(F_t\\) and \\(s_a\\).\nRecall that catchability (\\(q\\)) is the effect of of a unit of fishing effort (\\(E\\)) directed on the population, with the effect measured as the exponential rate of fishing mortality imposed on the population over a time interval \\(t\\):\n\\[\nF_t = q E_t\n\\tag{2}\\]\nConsidering that catchability and selectivity have a relationship with fishing mortality, Eq 1 & 2 can be combined:\n\\[\nF_{t,a} = s_a q E_t; \\hspace{4mm} q_a = s_a  q\n\\tag{3}\\]\nSelectivity then plays an essential role as a component of the survival equation in abundance at age:\n\\[\nN_{t,a} = N_{t-1,a-1}e^{-(F_{t-1} s_{a-1} + M_{t-1,a-1})}\n\\tag{4}\\]\n\n\\(N_{t,a}\\) is the abundance of survivors of an age class at the end of year \\(t\\)\n\nEq 4 is the primary process equation for all age-structured stock assessment models."
  },
  {
    "objectID": "notes/selectivity.html#selectivity-functions",
    "href": "notes/selectivity.html#selectivity-functions",
    "title": "Selectivity",
    "section": "Selectivity functions",
    "text": "Selectivity functions\nThere are several forms of fishing selectivity. Sampson and Scott (2012) defined four categories:\n\nAsymptotic: the oldest age classes are fully vulnerable 1a. Knife-edged: the simplest form of asymptotic form\nIncreasing: selection increases with age\nSaddle: there is at least one local minimum selection in the intermediate range of age classes\nDomed: the age for maximum selectivity (\\(s = 1\\)) is imtermediate in the range of age classes\n\n\n\nLogistic\nAsymptotic selectivity is often modeled using a logistic function. There are many variations of the logistic selectivity function.\n\\[\ns_a = \\dfrac{1}{1 + exp(-\\sigma_s (a - a_{50}))}\n\\]\n\n\\(\\sigma_s\\) is the logistic slope parameter\n\\(a_{50}\\) is the age of 50% vulnerability to the fishery (i.e., \\(s_{a_{50}} = 0.5\\))\n\nAnother parameterization of logistic selectvity uses parameters \\(a_{50}\\) and \\(a_{95}\\), which represent the ages where a fish has a probability 50% or 95% chance of being captured.\n\\[\ns_a = \\dfrac{1}{1+exp\\left( -log(19)\\left(\\dfrac{a - a_{50}}{a_{95} - a_{50}}\\right) \\right)}\n\\]\n\n\n\n\n\n\nWhy log(19)?\n\n\n\n\n\nWe need to ensure that the logistic function equals 0.95 when \\(a = a_{95}\\) and equals 0.5 when \\(a = a_{50}\\). Think about the odds of being captured:\n\nThe exponent of the log odds equals the odds ratio\nThe odds ratio is the probability of an event (i.e., getting captured) happening over the probablity of it not happening\n\nThus, the log-odds ratio for the age at which we have a 95% probability of getting captured is \\(log(\\dfrac{0.95}{0.05})\\). This can be rewritten as \\(log(\\dfrac{19/20}{1/20})\\), which then simplifies to \\(log(19)\\).\nThis is not necesssary for \\(a_{50}\\) because the odds ratio of two events with 50% probability is equal to zero.\n\n\n\n\n\nDouble logistic\nThe six parameter version of the double normal selectivity function can capture both asymptotic and dome-shaped shapes (commonly used in Stock Synthesis; Methot and Wetzel, 2013). The double normal has three components connected by steep logistic “joiners” to provide overall differentiability:\n\\[\ns_a = {asc}_a (1-j_{1,a}) + j_{1,a}((1-j_{2,a}) + j_{2,a} {dsc}_a)\n\\]\n\n\\({asc}_a\\) is the ascending limb\n\n\\[\n{asc}_a = p_5 + (1-p_5)\\left(e^{-(a - p_1)^2 / e^{p_3}} - e^{{p_1}^2 / e^{p_3}} \\right) / \\left(1 - e^{{p_1}^2 / e^{p_3}} \\right)\n\\]\n\n\\({dsc}_a\\) is the descending limb\n\n\\[\n{dsc}_a = 1 + (p_6 - 1)\\left(e^{-(a - \\gamma)^2 / e^{p_4}} - 1 \\right) / \\left(e^{-(A-\\gamma)^2 / e^{p_4}} - 1 \\right)\n\\]\n\n\\(j_{1,a}\\) is the first joiner function\n\n\\[\nj_{1,a} = \\dfrac{1}{\\left(1+e^{-20(a-p_1)/(1+|a-p_1|)}\\right)}\n\\]\n\n\\(j_{2,a}\\) is the second joiner function\n\n\\[\nj_{2,a} = \\dfrac{1}{\\left(1+e^{-20(a-\\gamma)/(1+|a-\\gamma|)}\\right)}\n\\]\n\n\\(p_1\\) is the age at which selectivity=1 starts\n\\(\\gamma\\) is the age at which selecitivity=1 ends and is defined as:\n\n\\[\n\\gamma = p_1 + 1 + \\left ( \\dfrac{0.99 A - p_1 - 1}{1 + e^{-p_2}} \\right)\n\\]\n\n\\(p_2\\) determines the age at which selectivity=1 ends (the width of the “top”; \\(\\gamma\\) is the end point)\n\\(p_3\\) determines the slope of the ascending section\n\\(p_4\\) determines the slope of the descending section\n\\(p_5\\) is the selectivity at age 0 (in logit-space)\n\\(p_6\\) is the selectivity at age \\(A\\) (in logit-space)\n\nThe double normal can mimic the asymptotic selectivity function by setting \\(p_6 = 1\\).\n\n\nGamma\nDome-shaped selectivity can be represented using a gamma function: \\[\ns_a = \\dfrac{a}{a_{max}}^{a_{max}/p} e^{(a_{max}-a)/p}; \\hspace{6mm} p = 0.5 \\left[\\sqrt{{a_{max}}^2 + 4\\gamma^2}- a_{max}\\right]\n\\]\n\n\\(a_{max}\\) is the full vulnerability to the fishery (i.e., \\(s_{a_{max}}\\) = 1)\n\\(\\gamma\\) is the gamma slope parameter"
  },
  {
    "objectID": "notes/selectivity.html#sensitivities-of-selectivity",
    "href": "notes/selectivity.html#sensitivities-of-selectivity",
    "title": "Selectivity",
    "section": "Sensitivities of selectivity",
    "text": "Sensitivities of selectivity\nThe form of selectivity is assumed in various stock assessment models. \\(F_{t,a}\\) can either be directly estimated or derived from estimated paramters.\n\nCatch curve\n\nEstimates total mortatliy as the negative of log-linear slope in eq 4 by assuming full selectiivty for a range of ages, usually from a middle age to oldest age (i.e., knife-edge selectivity)\nChapman and Robson, 1960\n\nVirtual population analysis (VPA)\n\nAssumes the selectivity of oldest age relative to a younger age to estimate \\(N_{t,a}\\) to derive \\(F_{t,a}\\)\nSelectivity in the most recent year is similar to previous years\nAge range of full vulnerability is often assumed to derive \\(F_t\\) (i.e., knife-edge selectivity)\nShepherd and Pope, 2002\n\nStatistical catch at age (SCAA)\n\nSeparability (eq 1) - estimate a time series of \\(F_t\\) and selectivity (\\(s_a\\)), either as estimated parameters or derived from functional selectivity functions\nMaunder and Punt, 2013"
  },
  {
    "objectID": "notes/selectivity.html#references",
    "href": "notes/selectivity.html#references",
    "title": "Selectivity",
    "section": "References",
    "text": "References\nCadrin, S.X., DeCelles, G.R. and Reid, D. (2016). Informing fishery assessment and management with field observations of selectivity and efficiency. Fisheries Research, 184, 9-17.\nChapman, D., & Robson, D. S. (1960). The analysis of a catch curve. Biometrics, 354-368.\nMaunder, M. N., & Punt, A. E. (2013). A review of integrated analysis in fisheries stock assessment. Fisheries research, 142, 61-74.\nMethot Jr, R. D., & Wetzel, C. R. (2013). Stock synthesis: a biological and statistical framework for fish stock assessment and fishery management. Fisheries Research, 142, 86-99.\nMillar, R. B., & Fryer, R. J. (1999). Estimating the size-selection curves of towed gears, traps, nets and hooks. Reviews in Fish Biology and Fisheries, 9, 89-116.\nSampson, D. B., & Scott, R. D. (2012). An exploration of the shapes and stability of population–selection curves. Fish and Fisheries, 13(1), 89-104.\nShepherd, J. G., & Pope, J. G. (2002). Dynamic pool models I: Interpreting the past using Virtual Population Analysis. Handbook of Fish Biology and Fisheries: Fisheries, 2, 127-163."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "tutorials",
    "section": "",
    "text": "homepage",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "guides/rtmb_intro.html",
    "href": "guides/rtmb_intro.html",
    "title": "RTMB Introduction",
    "section": "",
    "text": "RTMB is a new package that provides a native R interface for a subset of TMB so you can avoid coding in C++\nDeveloped by Kasper Kristensen (DTU-Aqua)\n\nSee https://kaskr.r-universe.dev/RTMB\n\nBecause code is all in R, both easier to code and for others to read that code - a game changer!\nA game changer if you know how to code in R, create an objective f(x) for your model\nNo compiling or compiling errors! (.dll files)\nBottom line: less time developing and testing models, more intuitive code"
  },
  {
    "objectID": "guides/rtmb_intro.html#what-is-rtmb",
    "href": "guides/rtmb_intro.html#what-is-rtmb",
    "title": "RTMB Introduction",
    "section": "",
    "text": "RTMB is a new package that provides a native R interface for a subset of TMB so you can avoid coding in C++\nDeveloped by Kasper Kristensen (DTU-Aqua)\n\nSee https://kaskr.r-universe.dev/RTMB\n\nBecause code is all in R, both easier to code and for others to read that code - a game changer!\nA game changer if you know how to code in R, create an objective f(x) for your model\nNo compiling or compiling errors! (.dll files)\nBottom line: less time developing and testing models, more intuitive code"
  },
  {
    "objectID": "guides/diagnostics.html",
    "href": "guides/diagnostics.html",
    "title": "Model convergence and diagnostics for non-linear models",
    "section": "",
    "text": "This tutorial discusses what to check to make sure your model is consistent with convergence diagnostics and is estimable. While this tutorial is focused on TMB/RTMB functions, this checklist can be applied to other non-linear models coded in other programs (e.g., ADMB).",
    "crumbs": [
      "Guides",
      "Model convergence and diagnostics"
    ]
  },
  {
    "objectID": "guides/diagnostics.html#checklist",
    "href": "guides/diagnostics.html#checklist",
    "title": "Model convergence and diagnostics for non-linear models",
    "section": "1 Checklist:",
    "text": "1 Checklist:\nThis is a checklist of convergence checks and diagnostics that should be conducted at minimum to verify a model:\n Model is executable (i.e., check objective function and gradients) \n The convergence message from RTMB indicates that the diagnostics are consistent with convergence (= 0) \n The Hessian matrix is positive definite \n Standard errors for model estimates are reasonable \n Alternative parameter starting points result in the same final parameter estimates (i.e., jitter test) \n Likelihood profiles for important parameters are reasonable, e.g.: \n         Initial abundance \n         Recruitment \n         Selectivity \n \nIf all of these checks pass, this indicates that the model is consistent with convergence diagnostics and is estimable. It is necessary for the model to pass all these checks. However, these checks are not sufficient for accepting model results. There are additional model diagnostics that should be checked to determine your final model:\n\n1.1 Additional things to check:\nFit vs data\n Confidence intervals \n Residuals \n Retrospective analysis \n Leave-out/jack knife runs \n Simulation test",
    "crumbs": [
      "Guides",
      "Model convergence and diagnostics"
    ]
  },
  {
    "objectID": "guides/diagnostics.html#additional-information",
    "href": "guides/diagnostics.html#additional-information",
    "title": "Model convergence and diagnostics for non-linear models",
    "section": "2 Additional information:",
    "text": "2 Additional information:\n\n2.1 Creating the objective function in RTMB\nSay you construct an objective function called obj using f as the model function and par as a list of initial parameter values. Using RTMB::MakeADFun, you can create the objective function:\n\nobj &lt;- RTMB::MakeADFun(f, par)\n\nYou need to check if the objective function will run before running an optimizer. You can look at this by checking if the objective function produces a likelihood and if a gradient is calculated for each parameter:\n\n# check likelihood\nobj$fn()\n\n# check gradients\nobj$gr()\n\n\n\n\n\n\n\nWhat are gradients\n\n\n\n\n\nGradients are the partial derivatives of the objective function with respect to the model parameters (goes into one vector - obj$gr()). These partial derivatives indicate how the objective function changes (direction and magnitude) as each parameter varies. This provides information for optimization algorithms to adjust the parameters iteratively to minimize or maximize the objective function.\n\n\n\nIf the model is estimable, it will calculate a likelihood based on the initial parameters. Each parameter should also provide a gradient value. If the gradient of a parameter = 0 or NA, this means that the model is not able to estimate that parameter or the parameter is not being used in the model.\nIf the checks on the objective function are successful, you can run the objective function with an optimizer using the nlminb function and opt is the output:\n\nopt &lt;- nlminb(obj$par, obj$fn, obj$gr)\n\n\n\n2.2 Convergence message\n\n# check if the model is converged\nopt$convergence\n# check type of convergence\nopt$message\n\nIf the diagnostics are consistent with convergence, then opt$convergence = 0. If the model did not converge, opt$convergence = 1. There can be some reasons why the model failed to converge (check opt$message for convergence message):\n\nsingular convergence: model is likely overparameterized (too complex for the data, the data does not contain enough information to estimate the parameters reliably)\nfalse convergence: likelihood may be discontinuous (this could be related to the estimation of the parameters)\n\nYou may encounter messages like these:\n\nWarning messages:\n1: In nlminb(start = par, objective = fn, gradient = gr) :\n  NA/NaN function evaluation\n\nThis does not necessarily mean the model is not converged. This means that the optimizer wandered off into a bad region for a while (i.e., NAs/NaNs in the estimates) and may have gotten back out. As long as it is back in a good region by the end of the optimization, then it may be fine. However, this should be evaluated with caution.\n\n\n2.3 Hessian matrix\n\n\n\n\n\n\nWhat is a Hessian matrix?\n\n\n\n\n\nA Hessian matrix is a square matrix of second-order partial derivatives of the objective function. In other words, it contains information about how the rate of change of each parameter with respect to every other parameter changes.\nThis represents the curvature of the likelihood surface and is used to calculate estimates of uncertainty for all the estimated model parameters and chosen derived quantities.\n\nInverting the negative Hessian gives us the covariance matrix, which provides a measure of parameter uncertainty.\nThe diagonal elements of the covariance matrix (i.e., inverse of the Hessian matrix) represent the variance of individual parameters.\nThe square root of the diagonal elements (i.e., variance) gives standard errors of the parameter estimates.\n\n\n\n\nThe Hessian matrix will not be invertible if the negative log likelihood is not a true minimum. This usually occurs when the model is mis-specified, which could either mean that the model has been written incorrectly so the objective function is not differentiable/estimable with respect to all the parameters. Or the estimated parameters are confounded or overparameterized (i.e., too complex for the data). RTMB will warn you about a non-positive definite Hessian matrix.\n\n\n2.4 Standard errors\nIf the standard errors for the parameter estimates are high, this suggests that the model is not fully converged. This can mean:\n\nlow precision: there is a wide range of plausible values for the parameters\nlack of stability in the estimation of the parameter\noverfitting: model may be too complex and is capturing noise in the data rather than true underlying patterns\n\nConsiderations to the model formulation and parameter estimates should be made if the standard errors are too high and unreasonable.\n\nsdrep &lt;- sdreport(obj)\nsdrep\n\n\n\n2.5 Jitter test\n\n\n2.6 Likelihood profile\n\n\n2.7 Fit vs data\n\n\n2.8 Confidence intervals\n\n\n2.9 Residuals\n\n\n2.10 Leave-out runs\n\n\n2.11 Simulation test",
    "crumbs": [
      "Guides",
      "Model convergence and diagnostics"
    ]
  },
  {
    "objectID": "guides/intro_opt.html",
    "href": "guides/intro_opt.html",
    "title": "Introduction to Automatic Differentiation",
    "section": "",
    "text": "The uncertainties of the model and parameters imply that there will always exist a discrepancy between our observations and predictions produced by the model."
  },
  {
    "objectID": "guides/intro_opt.html#mathematical-and-statistical-models",
    "href": "guides/intro_opt.html#mathematical-and-statistical-models",
    "title": "Introduction to Automatic Differentiation",
    "section": "Mathematical and statistical models",
    "text": "Mathematical and statistical models\nThe objective function is used to define some value that represents the discrepancy between observations and their corresponding model values. In statistics, this value is usually expressed in terms of probability, and referred to as the likelihood value. The optimizer uses a set of computational/mathematical/statistical rules and procedures (or algorithms) to find the best parameter set so that the objective function value is almost zero."
  },
  {
    "objectID": "guides/naming.html",
    "href": "guides/naming.html",
    "title": "Naming convention - data and parameters",
    "section": "",
    "text": "obs_xx observed data\nn_year\nyears\nn_age\nages\nlinf\nvbk\nto\nla\nwa\nmat\nfec\nM\nobs_ct\nobs_eff\nobs_comp\nneff"
  },
  {
    "objectID": "guides/naming.html#data",
    "href": "guides/naming.html#data",
    "title": "Naming convention - data and parameters",
    "section": "",
    "text": "obs_xx observed data\nn_year\nyears\nn_age\nages\nlinf\nvbk\nto\nla\nwa\nmat\nfec\nM\nobs_ct\nobs_eff\nobs_comp\nneff"
  },
  {
    "objectID": "guides/naming.html#parameters",
    "href": "guides/naming.html#parameters",
    "title": "Naming convention - data and parameters",
    "section": "Parameters",
    "text": "Parameters\n\nlog_xx log space data/parameters\nr_init\nar\nbr\nsig\nsel_p1\nsel_p2\nq\nsdr\nsdc"
  },
  {
    "objectID": "guides/naming.html#model",
    "href": "guides/naming.html#model",
    "title": "Naming convention - data and parameters",
    "section": "Model",
    "text": "Model\n\nF\nssb\nct\njnll"
  },
  {
    "objectID": "guides/stock_assessment.html",
    "href": "guides/stock_assessment.html",
    "title": "Stock assessment - how to set up R script",
    "section": "",
    "text": "This is a tutorial of how to set up script for running a stock assessment model. This is the format that all stock assessment scripts written in R/RTMB and from the QFC will use."
  },
  {
    "objectID": "guides/stock_assessment.html#r-script-header",
    "href": "guides/stock_assessment.html#r-script-header",
    "title": "Stock assessment - how to set up R script",
    "section": "R script header",
    "text": "R script header\nFirst, create comments that has the model name (if it has a specific name) and any information on the stock and location, modeler’s name, and any important notes on the model. Put dates if you are not using version control (i.e., not using GitHub). Delete any old comments that are not relevant to the most up-to-date model. Right after the comments, put library(RTMB) to open the RTMB R package.\n\n# Model name and information on stock and location\n# Stock assessor name(s) (DD-MM-YYYY)\n# any notes on model should be here, delete any old notes\n\nlibrary(RTMB)"
  },
  {
    "objectID": "guides/stock_assessment.html#data-and-parameters",
    "href": "guides/stock_assessment.html#data-and-parameters",
    "title": "Stock assessment - how to set up R script",
    "section": "Data and parameters",
    "text": "Data and parameters\nSet up the data list. For RTMB, the data needs to go into a single list, which will be called data. For consistency, keep the names of the variables/data inputs the same as listed here. See [] for naming convention.\n\ndat &lt;- load(\"data_file.RData\")    # data for stock assessment model\ndata &lt;- list()                    # all data for model should go into list called \"data\"\ndata$years &lt;- dat$fyear:dat$lyear \ndata$n_year &lt;- length(data$years)\ndata$ages &lt;- dat$fage:dat$lage \ndata$n_age &lt;- length(data$ages)\n### etc\n\nRight after the data, set up a single list for the parameters, which will be called par. Again, see naming convention here: [].\n\npar &lt;- list()\npar$log_rinit &lt;- 11\npar$log_q &lt;- -1\npar$sel_p1 &lt;- log(7)\npar$sel_p2 &lt;- log(5)\n### etc\n\nIf there are any additional functions that are required to run the model, put it after the parameters and before the function for the assessment model."
  },
  {
    "objectID": "guides/stock_assessment.html#creating-objective-function-i.e.-the-stock-assessment-model",
    "href": "guides/stock_assessment.html#creating-objective-function-i.e.-the-stock-assessment-model",
    "title": "Stock assessment - how to set up R script",
    "section": "Creating objective function (i.e., the stock assessment model)",
    "text": "Creating objective function (i.e., the stock assessment model)\nCreate the function for the objective function (i.e., stock assessment model). Call this function f. The only argument required is par, which is the parameter list. Note that data is not necessary in the function argument.\nThe first line should be the function getAll(data, par), which is a function that makes all the list of elements of data and parameters visible inside the function so that one could write years instead of data$years. The next line contains \"[&lt;-\" &lt;- ADoverload(\"[&lt;-\"), which helps work around limitations in R’s method dispatch system (e.g., R can’t combine numeric and ADvector classes).\n\nf &lt;- function(par) {\n  getAll(data, par)\n  \"[&lt;-\" &lt;- ADoverload(\"[&lt;-\")\n\n...\n}\n\nNext, put the tranformation of parameters (e.g., parameters in log space). Note that the name of the tranformed parameter should be different than the initial parameter in the par list.\n\nf &lt;- function(par) {\n...\n\n  ## Transform parameters\n  rinit &lt;- exp(log_rinit)\n  ### etc\n\n...\n}\n\n[Sections…]\nThe last part of the stock assessment model (the f function) will be the report section and the value that will be returned from running the function. The REPORT() function tells RTMB that we want to report a calculation from the model. The ADREPORT() function tells RTMB that we want uncertainties for this intermediate calculation from the model. Note that using ADREPORT() will slow down the model run. The value within return() should always be the joint negative log likelihood (jnll) in any stock assessment model.\n\nf &lt;- function(par) {\n...\n\n  ## Report and AD report section\n  REPORT(xx1)\n  REPORT(xx2)\n  ADREPORT(xx)\n\n  return(jnll)\n}"
  },
  {
    "objectID": "guides/stock_assessment.html#set-up-the-objective-function",
    "href": "guides/stock_assessment.html#set-up-the-objective-function",
    "title": "Stock assessment - how to set up R script",
    "section": "Set up the objective function",
    "text": "Set up the objective function\nWe then have to set up the objective function and define the fixed and/or random effects. The objective function (i.e., the assessment model) f and parameters par are processed by RTMB using the call MakeADFun(f, par).\n\nobj &lt;- MakeADFun(f, par)\n\nRandom effects can be included using the argument random = c(\"p1\", \"p2). A component of the parameter list (par) is marked as random if its name is matched by any of the parameters of the vector random.\n\nobj &lt;- MakeADFun(f, par, random = c(\"log_rinit\", \"log_q\"))\n\nIf some parameters are specified as random effects, these will be integrated out of the objective function via the Laplace approximation. In this situation, the functions fn and gr perform an optimization of random effects of each function evaluation, which is referred to as the “inner optimization”.\nFixed parameters can be included in the argument map = list(\"par1\" = as.factor(NA)). A map is a named list of factors with the following properties:\n\nnames(map) is a subset of names(par)\nFor a parameter “p” length(map$p) equals length(par$p)\nParameter entries with NAs in the factor are fixed\n\n\nobj &lt;- MakeADFun(f, par, map = list(\"log_rinit\" = as.factor(NA)))"
  },
  {
    "objectID": "guides/stock_assessment.html#fitting-the-model",
    "href": "guides/stock_assessment.html#fitting-the-model",
    "title": "Stock assessment - how to set up R script",
    "section": "Fitting the model",
    "text": "Fitting the model\nWe optimize the model using nlminb. This function at minimum needs initial values for the parameters to be optimized (obj$par), the objective function to be minimized (obj$fn), and gradient of the objective function (obj$gr).\n\nopt &lt;- nlminb(obj$par, obj$fn, obj$gr)"
  },
  {
    "objectID": "guides/stock_assessment.html#calculating-model-outputs",
    "href": "guides/stock_assessment.html#calculating-model-outputs",
    "title": "Stock assessment - how to set up R script",
    "section": "Calculating model outputs",
    "text": "Calculating model outputs\nUncertainties are calculated using sdreport(obj). This should be saved into an object called sdr. The function sdreport() is used to calculate standard deviations of all model parameters, including non linear functions of random effects and parameters/estimates specified through ADREPORT().\n\nsdr &lt;- sdreport(obj)\n\nThe quantities within the objective function (i.e., anything within REPORT()) can be extracted using obj$report(opt$par). The parameters and standard errors can be extracted as separate lists using as.list(). Pass report = TRUE to get ADREPORTed quantities.\n\nres &lt;- obj$report(opt$par) # REPORT estimates\nres &lt;- as.list(sdr, \"Est\") # get parameter estimates\nres &lt;- as.list(sdr, \"Std\") # parameter uncertainties\n# if ADREPORT()\nresl &lt;- as.list(sdr, \"Est\", report = TRUE)      # ADREPORT estimates\nresl_sd &lt;- as.list(sdrep, \"Std\", report = TRUE) # ADREPORT uncertainties\n\n[plots…]\n[diagnostics…]"
  },
  {
    "objectID": "guides/stock_assessment.html#entire-script",
    "href": "guides/stock_assessment.html#entire-script",
    "title": "Stock assessment - how to set up R script",
    "section": "Entire script",
    "text": "Entire script\n\n# Model name and information on stock and location\n# Stock assessor name(s) (DD-MM-YYYY)\n# any notes on model should be here, delete any old notes\n\nlibrary(RTMB)\n# Data ----\ndat &lt;- load(\"data_file.RData\")    # data for stock assessment model\ndata &lt;- list()                    # all data for model should go into list called \"data\"\ndata$years &lt;- dat$fyear:dat$lyear \ndata$n_year &lt;- length(data$years)\ndata$ages &lt;- dat$fage:dat$lage \ndata$n_age &lt;- length(data$ages)\n### etc\n\n# Parameters ----\npar &lt;- list()\npar$log_rinit &lt;- 11\npar$log_q &lt;- -1\npar$sel_p1 &lt;- log(7)\npar$sel_p2 &lt;- log(5)\n### etc\n\n# Additional functions ----\nadd_function &lt;- function(arguments) {\n  ...\n  return(out)\n}\n\n# Stock assessment model ----\nf &lt;- function(par) {\n  getAll(data, par)\n  \"[&lt;-\" &lt;- ADoverload(\"[&lt;-\")\n\n  ## Transform parameters\n  rinit &lt;- exp(log_rinit)\n  ### etc\n\n  ## Sections\n\n  ## Report and AD report section\n  REPORT(xx1)\n  REPORT(xx2)\n  ADREPORT(xx)\n\n  return(jnll)\n}\n\n# Run model ----\nobj &lt;- MakeADFun(f, par)\nopt &lt;- nlminb(obj$par, obj$fn, obj$gr)\nsdr &lt;- sdreport(obj)\nres &lt;- obj$report(opt$par) # REPORT estimates\nres &lt;- as.list(sdr, \"Est\") # get parameter estimates\nres &lt;- as.list(sdr, \"Std\") # parameter uncertainties\n# if ADREPORT()\nresl &lt;- as.list(sdr, \"Est\", report = TRUE)      # ADREPORT estimates\nresl_sd &lt;- as.list(sdrep, \"Std\", report = TRUE) # ADREPORT uncertainties\n\n# Plots ----\n\n# Diagnostics ----"
  },
  {
    "objectID": "notes/equil_recruit.html",
    "href": "notes/equil_recruit.html",
    "title": "Equilibrium Recruitment",
    "section": "",
    "text": "Fisheries management decisions are often based on abundance relative to reference points. The most common reference point is the population size at which MSY is achieved. The fully-selected fishing mortality corresponding to MSY (\\(F_{MSY}\\)), which is defined as the fishing mortality at which yield is maximized.\nYield refers to the total amount of fish harvested from a fishery within a given period of time, which is typically measured of the productivity or output of the fishery in terms of weight or number of fish caught.\nNote that yield-per-recruit is different than yield. Yield-per-recruit (YPR) is a measure of the average contribution of an individual fish to the total yield of the fishery. It focuses on the productivity of individual fish within the population rather than the total catch.\nThe recruitment as a function of \\(F\\) (\\(R_F\\)) depends on the assumed form of the stock-recruitment relationship. The unfished spawning biomass (\\(S_0\\)) is the expected spawning biomass for one unfished recruit (i.e., spawner biomass per recruit; \\(\\phi_0\\)) times the number of recruits (i.e., the unfished recruitment; \\(R_0\\))"
  },
  {
    "objectID": "notes/equil_recruit.html#stock-recruitment-functions-in-terms-of-alpha-and-beta",
    "href": "notes/equil_recruit.html#stock-recruitment-functions-in-terms-of-alpha-and-beta",
    "title": "Equilibrium Recruitment",
    "section": "Stock recruitment functions in terms of alpha and beta",
    "text": "Stock recruitment functions in terms of alpha and beta\n\nPer-recruit calculations\nYield (\\(Y\\)) can be defined as a function of fully-selected fishing mortality:\n\\[\nY_F = {YPR}_F R_F\n\\tag{1}\\]\n\n\\(YPR_F\\) is yield-per-recruit as a function of fishing mortality\n\\(R_F\\) is recruitment as a function of fishing mortality.\n\nYPR is defined as:\n\\[\n{YPR}_F = \\sum_a w_a \\dfrac{s_a F}{Z_a}N_a (1-e^{-Z_a})\n\\tag{2}\\]\n\n\\(w_a\\) is the weight at age\n\\(s_a\\) is the selectivity at age\n\\(Z_a\\) is the total mortality at age\n\n\\[\nZ_a = M + s_a F\n\\tag{3}\\]\n\n\\(N_a\\) is the number at age relative to the number of fish of age 0\n\n\\[\nN_{a}=\\left\\{\\begin{array}{ll}\n1 & \\text { if } a=0 \\\\\nN_{a-1} e^{-Z_{a-1}} & \\text { if } 0&lt;a&lt;x \\\\\n\\dfrac{N_{A-1} e^{-Z_{A-1}}}{1-e^{-Z_{A}}} & \\text { if } a=A\n\\end{array}\\right.\n\\tag{4}\\]\nThe unfished spawning biomass (\\(S_0\\)) is defined as:\n\\[\nS_0 = \\phi_0 R_0\n\\tag{5}\\]\nThe unfished recruitment (\\(R_0\\)) can be obtained by some algebra with eq 5:\n\\[\nR_0 = \\dfrac{S_0}{\\phi_0}\n\\tag{6}\\]\nThis then also means that the spawner per biomass recruit (\\(\\phi_0\\)) can also be obtained:\n\\[\n\\phi_0 = \\dfrac{S_0}{R_0}\n\\tag{7}\\]\nThe same relationship in eq 5 applies for equilibrium spawning biomass:\n\\[\nS_F = \\phi_F R_F\n\\tag{8}\\]\nSpawner biomass per recruit as a function of \\(F\\) is defined as:\n\\[\n\\phi_F = \\sum_a f_a N_a\n\\tag{9}\\]\n\n\\(f_a\\) is fecundity at age\n\n\n\nBeverton-Holt\nRecruitment as a function of \\(F\\) for Beverton-Holt is defined as:\n\\[\nR_F = \\dfrac{S_F}{\\alpha + \\beta S_F}\n\\tag{10}\\]\nSubstitute eq 8 into eq 10 and solve for \\(R_F\\) to get the stock recruitment relationship in terms of \\(\\phi_F\\): \\[\nR_F = \\dfrac{\\phi_F - \\alpha}{\\beta\\hspace{0.5mm} \\phi_F}\n\\tag{11}\\]\nUnfished recruitment for Beverton-Holt can be defined the same eq 10:\n\\[\nR_0 = \\dfrac{S_0}{\\alpha + \\beta S_0}\n\\tag{12}\\]\nNow we need a definition for \\(\\alpha\\) and \\(\\beta\\), the stock recruitment parameters. These only vary by \\(R_0\\) and steepness (\\(h\\)), which is defined as the expected recruitment at 20% of \\(S_0\\) (hence \\(0.2 S_0\\)):\n\\[\nh R_0 = \\dfrac{0.2 S_0}{\\alpha + 0.2 \\beta S_0}\n\\tag{13}\\]\nWith some extra algebra, we can obtain \\(\\alpha\\) and \\(\\beta\\) in terms of steepness (\\(h\\)), unfished recruitment (\\(R_0\\)), and unfished spawning biomass (\\(S_0\\)):\n\\[\n\\alpha = \\phi_0 \\left(\\dfrac{1-h}{4h}\\right)\n\\tag{14}\\]\n\n\n\n\n\n\nAlgebra on alpha\n\n\n\n\n\n\n\n\n\n\\[\n\\beta = \\dfrac{5h-1}{4h R_0}\n\\tag{15}\\]\n\n\n\n\n\n\nAlgebra on beta\n\n\n\n\n\n\n\n\n\n\n\nRicker\nRecruitment as a function of \\(F\\) for Ricker is defined as:\n\\[\nR_F = \\alpha S_F e^{-\\beta S_F}\n\\tag{16}\\]\nSubstitute eq 8 into eq 16 and solve for \\(R_F\\) to get the stock recruitment relationship in terms of \\(\\phi_F\\): \\[\nR_F = \\dfrac{log(\\alpha \\hspace{0.5mm} \\phi_F)}{\\beta \\hspace{0.5mm} \\phi_F}\n\\tag{17}\\]\nUnfished recruitment for Ricker can be defined the same eq 16:\n\\[\nR_0 = \\alpha S_0 e^{-\\beta S_0}\n\\tag{18}\\]\nNow we need a definition for \\(\\alpha\\) and \\(\\beta\\), the stock recruitment parameters. These only vary by \\(R_0\\) and steepness (\\(h\\)). Steepness can be included as:\n\\[\nh R_0 = 0.2 \\alpha S_0 e^{-0.2 \\beta S_0}\n\\tag{19}\\]\nWith some extra algebra, we can obtain \\(\\alpha\\) and \\(\\beta\\) in terms of steepness (\\(h\\)), unfished recruitment (\\(R_0\\)), and unfished spawning biomass (\\(S_0\\)):\n\\[\n\\alpha = \\dfrac{1}{\\phi_0} \\hspace{0.5mm} e^{\\dfrac{5 log(5h)}{4}}\n\\tag{20}\\]\n\\[\n\\beta = \\dfrac{log(5h)}{0.8 S_0}\n\\tag{21}\\]"
  },
  {
    "objectID": "notes/equil_recruit.html#stock-recruitment-functions-in-terms-of-steepness",
    "href": "notes/equil_recruit.html#stock-recruitment-functions-in-terms-of-steepness",
    "title": "Equilibrium Recruitment",
    "section": "Stock recruitment functions in terms of steepness",
    "text": "Stock recruitment functions in terms of steepness\nWe are going to define steepness (\\(h\\)) and unfished recruitment \\(R0\\) in terms of \\(\\alpha\\) and \\(\\beta\\), which is a reparameterization of the previous section. The per-recruit calculations are the same as the previous section.\n\nBeverton-Holt\nSteepness for the Beverton-Holt function is defined as:\n\\[\nh = \\dfrac{\\alpha \\hspace{0.5mm} \\phi_0}{4 + \\alpha \\hspace{0.5mm} \\phi_0}\n\\tag{22}\\]\nThe unfished recruitment (\\(R_0\\)) is defined as (similar to eq 11):\n\\[\nR_0 = \\dfrac{\\phi_0 - \\alpha}{\\beta\\hspace{0.5mm} \\phi_0}\n\\tag{23}\\]\nThe Beverton-Holt function in terms of \\(F\\), steepness (\\(h\\)), and unfished recruitment (\\(R_0\\)) becomes:\n\\[\nR_F = \\dfrac{S_F 4h R_0}{S_0 (1-h) + S_F(5h-1)}\n\\tag{24}\\]\n\n\nRicker\nSteepness for the Ricker function is defined as:\n\\[\nh = \\dfrac{(\\alpha \\hspace{0.5mm} \\phi_0)^{4/5}}{5}\n\\tag{25}\\]\nThe unfished recruitment (\\(R_0\\)) is defined as (similar to eq 17):\n\\[\nR_0 = \\dfrac{log(\\alpha \\hspace{0.5mm} \\phi_0)}{\\beta \\hspace{0.5mm} \\phi_0}\n\\tag{26}\\]\nThe Ricker function in terms of \\(F\\), steepness (\\(h\\)), and unfished recruitment (\\(R_0\\)) becomes:\n\\[\nR_F = \\dfrac{S_F}{\\phi_0} (5h)^{\\left( \\dfrac{5}{4} \\right)\\left(1- \\dfrac{S_F}{R_0 \\phi_0} \\right)}\n\\tag{27}\\]"
  },
  {
    "objectID": "notes/equil_recruit.html#stock-recruitment-functions-in-terms-of-compensation-ratio",
    "href": "notes/equil_recruit.html#stock-recruitment-functions-in-terms-of-compensation-ratio",
    "title": "Equilibrium Recruitment",
    "section": "Stock recruitment functions in terms of compensation ratio",
    "text": "Stock recruitment functions in terms of compensation ratio\nAn alternative estimation of recruitment uses compensation ratio (\\(CR\\)), which is defined as the ratio of \\(\\alpha\\) to the slope of the line drawn between the origin and the point on the stock-recruitment surve at which the stock is unfished (Goodyear, 1997; Myers et al., 1999).\n\\[\n\\]\n\nBeverton-Holt\n\\[\nCR = \\dfrac{4h}{1-h}\n\\]\n\\[\n\\alpha = \\dfrac{CR}{\\phi_{E_0}}\n\\]\n\\[\n\\beta = \\dfrac{\\alpha \\phi_{E_0} - 1}{R_0 \\phi_{E_0}}\n\\]\n\\[\nR_F = \\dfrac{\\alpha \\phi_{E_F} - 1}{\\beta \\phi_{E_F}}\n\\]\n\n\nRicker\n\\[\n\\alpha = \\dfrac{CR}{\\phi_{E_0}}\n\\]\n\\[\n\\beta = \\dfrac{log(\\alpha \\phi_{E_0})}{R_0 \\phi_{E_0}}\n\\]\n\\[\nR_F = \\dfrac{log(\\alpha \\phi_{E_F})}{\\beta \\phi_{E_F}}\n\\]"
  }
]