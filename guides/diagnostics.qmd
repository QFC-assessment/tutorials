---
title: "Model convergence and diagnostics for non-linear models"
format:
  html:
    toc: true
    page-layout: full
    css: styles.css
editor: visual
---

This tutorial discusses what to check to make sure your model is consistent with convergence diagnostics and is estimable. While this tutorial is focused on TMB/RTMB functions, this checklist can be applied to other non-linear models coded in other programs (e.g., ADMB).

## Checklist:

This is a checklist of convergence checks and diagnostics that should be conducted at minimum to verify a model:

-   <input type="checkbox" unchecked> Model is executable (i.e., check objective function and gradients) </input>
-   <input type="checkbox" unchecked> The convergence message from RTMB indicates that the diagnostics are consistent with convergence (`= 0`) </input>
-   <input type="checkbox" unchecked> The Hessian matrix is positive definite </input>
-   <input type="checkbox" unchecked> Standard errors for model estimates are reasonable </input>
-   <input type="checkbox" unchecked> Alternative parameter starting points result in the same final parameter estimates (i.e., jitter test) </input>
-   <input type="checkbox" unchecked> Likelihood profiles for important parameters are reasonable, e.g.: </input>
    -   <input type="checkbox" unchecked> Initial abundance </input>
    -   <input type="checkbox" unchecked> Recruitment </input>
    -   <input type="checkbox" unchecked> Selectivity </input>

If all of these checks pass, this indicates that the model is consistent with convergence diagnostics and is estimable. It is necessary for the model to pass all these checks. However, these checks are not sufficient for accepting model results. There are additional model diagnostics that should be checked to determine your final model:

### Additional things to check:

-   <input type="checkbox" unchecked> Fit vs data </input>
-   <input type="checkbox" unchecked> Confidence intervals </input>
-   <input type="checkbox" unchecked> Residuals </input>
-   <input type="checkbox" unchecked> Retrospective analysis </input>
-   <input type="checkbox" unchecked> Leave-out/jack knife runs </input>
-   <input type="checkbox" unchecked> Simulation test </input>

## Additional information:

### Creating the objective function in RTMB

Say you construct an objective function called `obj` using `f` as the model function and `par` as a list of initial parameter values. Using `RTMB::MakeADFun`, you can create the objective function:

```{r, eval = FALSE}
obj <- RTMB::MakeADFun(f, par)
```

You need to check if the objective function will run before running an optimizer. You can look at this by checking if the objective function produces a likelihood and if a gradient is calculated for each parameter:

```{r, eval = FALSE}
# check likelihood
obj$fn()

# check gradients
obj$gr()
```

::: {.callout-note collapse="true"}

## What are gradients

**Gradients** are the partial derivatives of the objective function with respect to the model parameters (goes into one vector - `obj$gr()`). These partial derivatives indicate how the objective function changes (direction and magnitude) as each parameter varies. This provides information for optimization algorithms to adjust the parameters iteratively to minimize or maximize the objective function.

:::

If the model is estimable, it will calculate a likelihood based on the initial parameters. Each parameter should also provide a gradient value. If the gradient of a parameter = 0 or NA, this means that the model is not able to estimate that parameter or the parameter is not being used in the model.

If the checks on the objective function are successful, you can run the objective function with an optimizer using the `nlminb` function and `opt` is the output:

```{r, eval = FALSE}
opt <- nlminb(obj$par, obj$fn, obj$gr)
```

### Convergence message

```{r, eval = FALSE}
# check if the model is converged
opt$convergence
# check type of convergence
opt$message
```

If the diagnostics are consistent with convergence, then `opt$convergence = 0`. If the model did not converge, `opt$convergence = 1`. There can be some reasons why the model failed to converge (check `opt$message` for convergence message):

-   singular convergence: model is likely overparameterized (too complex for the data, the data does not contain enough information to estimate the parameters reliably)
-   false convergence: likelihood may be discontinuous (this could be related to the estimation of the parameters)

You may encounter messages like these:

```{r, eval = FALSE}
Warning messages:
1: In nlminb(start = par, objective = fn, gradient = gr) :
  NA/NaN function evaluation
```

This does not necessarily mean the model is not converged. This means that the optimizer wandered off into a bad region for a while (i.e., NAs/NaNs in the estimates) and may have gotten back out. As long as it is back in a good region by the end of the optimization, then it may be fine. However, this should be evaluated with caution.

### Hessian matrix

::: {.callout-note collapse="true"}

## What is a Hessian matrix?

A Hessian matrix is a square matrix of second-order partial derivatives of the objective function. In other words, it contains information about how the rate of change of each parameter with respect to every other parameter changes.

This represents the curvature of the likelihood surface and is used to calculate estimates of uncertainty for all the estimated model parameters and chosen derived quantities.

-   Inverting the negative Hessian gives us the covariance matrix, which provides a measure of parameter uncertainty.
-   The diagonal elements of the covariance matrix (i.e., inverse of the Hessian matrix) represent the variance of individual parameters.
-   The square root of the diagonal elements (i.e., variance) gives standard errors of the parameter estimates.

:::

The Hessian matrix will not be invertible if the negative log likelihood is not a true minimum. This usually occurs when the model is mis-specified, which could either mean that the model has been written incorrectly so the objective function is not differentiable/estimable with respect to all the parameters. Or the estimated parameters are confounded or overparameterized (i.e., too complex for the data). RTMB will warn you about a non-positive definite Hessian matrix.

### Standard errors

If the standard errors for the parameter estimates are high, this suggests that the model is not fully converged. This can mean:

-   low precision: there is a wide range of plausible values for the parameters
-   lack of stability in the estimation of the parameter
-   overfitting: model may be too complex and is capturing noise in the data rather than true underlying patterns

Considerations to the model formulation and parameter estimates should be made if the standard errors are too high and unreasonable.

```{r, eval = FALSE}
sdrep <- sdreport(obj)
sdrep
```

### Jitter test

### Likelihood profile

### Fit vs data

### Confidence intervals

### Residuals

### Leave-out runs

### Simulation test
